[{"content":"试验一下是否生效.。\n","permalink":"https://beardleon.github.io/posts/why/","summary":"\u003cp\u003e试验一下是否生效.。\u003c/p\u003e","title":"Why"},{"content":"命令：\nhugo new posts/note_name.md edit git add contents/posts/note_name.md git commit -m \u0026#34;msg\u0026#34; git push wait Github Actions ","permalink":"https://beardleon.github.io/posts/how_to_use_hugo/","summary":"\u003cp\u003e命令：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ehugo new posts/note_name.md\n\nedit\n\ngit add contents/posts/note_name.md\n\ngit commit -m \u0026#34;msg\u0026#34;\n\ngit push\n\nwait Github Actions\n\u003c/code\u003e\u003c/pre\u003e","title":"How_to_use_hugo"},{"content":"我还是很想要跟着前线做一些大模型相关的工作的，跨境电商是一个很好的方向，走走看？是否在主航线上呢？\n","permalink":"https://beardleon.github.io/posts/20250108_2/","summary":"\u003cp\u003e我还是很想要跟着前线做一些大模型相关的工作的，跨境电商是一个很好的方向，走走看？是否在主航线上呢？\u003c/p\u003e","title":"20250108_2"},{"content":"怎么样去做呢？ ","permalink":"https://beardleon.github.io/posts/20250108/","summary":"\u003ch2 id=\"怎么样去做呢\"\u003e怎么样去做呢？\u003c/h2\u003e","title":"20250108"},{"content":"总觉得需要搞个博客，记录最近的日常，写写内容，作为输出。\n","permalink":"https://beardleon.github.io/posts/say_something/","summary":"\u003cp\u003e总觉得需要搞个博客，记录最近的日常，写写内容，作为输出。\u003c/p\u003e","title":"突然想说点什么"},{"content":"大家好，现在是2023年9月30日。\n祝福大家中秋国庆双节快乐，一切顺利！\n","permalink":"https://beardleon.github.io/posts/mid-autumn/","summary":"\u003cp\u003e大家好，现在是2023年9月30日。\u003c/p\u003e\n\u003cp\u003e祝福大家中秋国庆双节快乐，一切顺利！\u003c/p\u003e","title":"Mid Autumn"},{"content":"Hi Everyone Hi There is Beard Leon, who‘s a James Harden\u0026rsquo;s fan.\nDesc Contact mail:\nEnd Bye-Bye.\n","permalink":"https://beardleon.github.io/posts/first/","summary":"\u003ch1 id=\"hi-everyone\"\u003eHi Everyone\u003c/h1\u003e\n\u003cp\u003eHi There is Beard Leon, who‘s a James Harden\u0026rsquo;s fan.\u003c/p\u003e\n\u003ch2 id=\"desc\"\u003eDesc\u003c/h2\u003e\n\u003ch2 id=\"contact\"\u003eContact\u003c/h2\u003e\n\u003cp\u003email:\u003c/p\u003e\n\u003ch2 id=\"end\"\u003eEnd\u003c/h2\u003e\n\u003cp\u003eBye-Bye.\u003c/p\u003e","title":"My Intro"},{"content":"Redis 深入浅出走进Redis https://mp.weixin.qq.com/s/ThVtw8TVuhxIyYxJy6sOWw 缓存穿透（redis无key）-压垮数据库 cache penetration （刺穿）\n问题描述：key对应的数据在数据源并不存在，每次针对此key的请求从缓存获取不到，请求都会压到数据源，从而可能压垮数据源。比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。\n解决方案：（1）对空值缓存：如果一个查询返回的数据为空（不管是数据是否不存在），我们仍然把这个空结果（null）进行缓存，设置空结果的过期时间会很短，最长不超过五分钟。（2）设置可访问的名单（白名单）：使用bitmaps类型定义一个可以访问的名单，名单id作为bitmaps的偏移量，每次访问和bitmap里面的id进行比较，如果访问id不在bitmaps里面，进行拦截，不允许访问。（3）采用布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmaps中，一个一定不存在的数据会被 这个bitmaps拦截掉，从而避免了对底层存储系统的查询压力。（加一层防护判断）（4）进行实时监控：当发现Redis的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，可以设置黑名单限制服务。\n缓存击穿（redis热点key突然过期）-大量并发访问单key-被击穿数据库 cache breakdown\n问题描述：key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。\n解决问题：（1）预先设置热门数据：在redis高峰访问之前，把一些热门数据提前存入到redis里面，加大这些热门数据key的时长。（淘宝提前热门缓存）（2）实时调整：现场监控哪些数据热门，实时调整key的过期时长。（3）使用锁：就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db；先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX）去set一个mutex key；当操作返回成功时，再进行load db的操作，并回设缓存,最后删除mutex key；当操作返回失败，证明有线程在load db，当前线程睡眠一段时间再重试整个get缓存的方法（搞个分布式锁，但一线程去访问db，阻塞其他的）。\n什么是缓存击穿 平常在高并发系统中，会出现大量的请求同时查询一个 key的情况，假如此时这个热 key刚好失效了，就会导致大量的请求都打到数据库上面去，这种现象就是缓存击穿。缓存击穿和缓存雪崩有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了DB，而缓存击穿则是指一个key非常热点，在不停的扛着高并发，高并发集中对着这一个点进行访问，如果这个key在失效的瞬间，持续的并发到来就会穿破缓存，直接请求到数据库，就像一个完好无损的桶上凿开了一个洞，造成某一时刻数据库请求量过大，压力剧增！\n如何解决 方法一我们简单粗暴点，直接让热点数据永远不过期，定时任务定期去刷新数据就可以了。不过这样设置需要区分场景，比如某宝首页可以这么做。 方法二为了避免出现缓存击穿的情况，我们可以在第一个请求去查询数据库的时候对他加一个互斥锁，其余的查询请求都会被阻塞住，直到锁被释放，后面的线程进来发现已经有缓存了，就直接走缓存，从而保护数据库。但是也是由于它会阻塞其他的线程，此时系统吞吐量会下降。需要结合实际的业务去考虑是否要这么做。 方法三\n方法三就是singleflight的设计思路，也会使用互斥锁，但是相对于方法二的加锁粒度会更细，这里先简单总结一下singleflight的设计原理，后面看源码在具体分析。\nsingleflightd的设计思路就是将一组相同的请求合并成一个请求，使用 map存储，只会有一个请求到达mysql，使用 sync.waitgroup包进行同步，对所有的请求返回相同的结果。 缓存雪崩（redis有多key无value）-多key被击穿 问题描述：key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。缓存雪崩与缓存击穿的区别在于这里针对很多key缓存，后者则是某一个key。\n解决方案：（1）构建多级缓存架构：nginx缓存 + redis缓存 +其他缓存（ehcache等）。（2）使用锁或队列：用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上（消息队列）。不适用高并发情况。（3）设置过期标志更新缓存：记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程在后台去更新实际key的缓存。（4）将缓存失效时间分散开：比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。\n持久化AOF \u0026amp; RDB Append- Only- File日志 默认不开启 RDB快照 AOF 文件的内容是操作命令（写命令）； RDB 文件的内容是二进制数据。 Append- Only- File持久化操作命令如何实现？ 如果 Redis 每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里，然后重启 Redis 的时候，先去读取这个文件里的命令，并且执行它，这不就相当于恢复了缓存数据了吗？\n这种保存写操作命令到日志的持久化方式，就是 Redis 里的 AOF( Append Only File ) 持久化功能，注意只会记录写操作命令，读操作命令是不会被记录的（读不被记录）\nAOF 日志文件其实就是普通的文本，我们可以通过 cat 命令查看里面的内容，不过里面的内容如果不知道一定的规则的话，可能会看不懂。\n「*3」表示当前命令有三个部分，每部分都是以「$+数字」开头，后面紧跟着具体的命令、键或值。然后，这里的「数字」表示这部分中的命令、键或值一共有多少字节。例如，「$3 set」表示这部分有 3 个字节，也就是「set」命令这个字符串的长度。\nAOF先执行后写日志（先做命令后AOF） 好处\nRedis 是先执行写操作命令后，才将该命令记录到 AOF 日志里的，这么做其实有两个好处。\n避免额外的检查开销。\n因为如果先将写操作命令记录到 AOF 日志里，再执行该命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到 AOF 日志里后，Redis 在使用日志恢复数据时，就可能会出错。\n而如果先执行写操作命令再记录日志的话，只有在该命令执行成功后，才将命令记录到 AOF 日志里，这样就不用额外的检查开销，保证记录在 AOF 日志里的命令都是可执行并且正确的。\n不会阻塞当前写操作命令的执行 ，因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。\n风险\n执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有丢失的风险 由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前写操作命令的执行，但是可能会给「下一个」命令带来阻塞风险(阻塞下一个） 将命令写入到日志的这个操作也是在主进程完成的（执行命令也是在主进程），也就是说这两个操作是同步的。\nAlways、EverySec、No三种日志写会硬盘策略 Redis 写入 AOF 日志的过程，如下图：\n日志流程：\n用户态 server.aof_buf缓冲区 内核态 cache 缓冲区 落盘 Redis 执行完写操作命令后，会将命令追加到 server.aof_buf 缓冲区； 然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘； 具体内核缓冲区的数据什么时候写入到硬盘，由内核决定 Redis 提供了 3 种写回硬盘的策略，控制的就是上面说的第三步的过程。\n在 redis.conf 配置文件中的 appendfsync 配置项可以有以下 3 种参数可填：\nAlways ，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘； Everysec(ond) ，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘； No ，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。 这 3 种写回策略都无法能完美解决「主进程阻塞」和「减少数据丢失」的问题，因为两个问题是对立的，偏向于一边的话，就会要牺牲另外一边，原因如下：\nAlways 策略的话，可以最大程度保证数据不丢失，但是由于它每执行一条写操作命令就同步将 AOF 内容写回硬盘，所以是不可避免会影响主进程的性能； No 策略的话，是交由操作系统来决定何时将 AOF 日志内容写回硬盘，相比于 Always 策略性能较好，但是操作系统写回硬盘的时机是不可预知的，如果 AOF 日志内容没有写回硬盘，一旦服务器宕机，就会丢失不定数量的数据。 Everysec 策略的话，是折中的一种方式，避免了 Always 策略的性能开销，也比 No 策略更能避免数据丢失，当然如果上一秒的写操作命令日志没有写回到硬盘，发生了宕机，这一秒内的数据自然也会丢失。 AOF重写机制 压缩 -\u0026gt; :大小超过阈值，读全表写kv到aof文件，替换原来的 (64MB)，后台子进程 bgrewriteaof做，避免性能影响\nAOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。\n如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。\nRedis 为了避免 AOF 文件越写越大，提供了 AOF 重写机制 ，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。\nAOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。\nAOF后台重写 写入 AOF 日志的操作虽然是在主进程完成的，因为它写入的内容不多，所以一般不太影响命令的操作。\n但是在触发 AOF 重写时，比如当 AOF 文件大于 64M 时，就会对 AOF 文件进行重写，这时是需要读取所有缓存的键值对数据，并为每个键值对生成一条命令，然后将其写入到新的 AOF 文件，重写完后，就把现在的 AOF 文件替换掉。\n这个过程其实是很耗时的，所以重写的操作不能放在主进程里。\nRedis 的 重写 AOF 过程是由后台子进程 bgrewriteaof来完成的 ，这么做可以达到两个好处：\n子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程； 子进程带有主进程的数据副本，这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生「写时复制」，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。 主进程在通过 fork 系统调用生成 bgrewriteaof 子进程时，操作系统会把主进程的「 页表 」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个\n这样一来，子进程就共享了父进程的物理内存数据了，这样能够 节约物理内存资源 ，页表对应的页表项的属性会标记该物理内存的权限为 只读 。\n不过，当父进程或者子进程在向这个内存发起写操作时，CPU 就会触发 写保护中断 ，这个写保护中断是由于违反权限导致的，然后操作系统会在「写保护中断处理函数」里进行 物理内存的复制 ，并重新设置其内存映射关系，将父子进程的内存读写权限设置为 可读写 ，最后才会对内存进行写操作，这个过程被称为「 写时复制( Copy On Write ) 」。\n还有个问题，重写 AOF 日志过程中，如果主进程修改了已经存在 key-value，此时这个 key-value 数据在子进程的内存数据就跟主进程的内存数据不一致了，这时要怎么办呢？\n为了解决这种数据不一致问题，Redis 设置了一个 AOF 重写缓冲区 ，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。\n在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会 同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」 。\n也就是说，在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作:\n两个缓冲区保障一致\n执行客户端发来的命令；\n将执行后的写命令追加到 「AOF 缓冲区」；\n将执行后的写命令追加到 「AOF 重写缓冲区」；\nAOF重写缓冲区追加到AOF缓冲区，覆盖\n当子进程完成 AOF 重写工作（ 扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志 ）后，会向主进程发送一条信号，信号是进程间通讯的一种方式，且是异步的。\n主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：\n将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致； 新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。 信号函数执行完后，主进程就可以继续像往常一样处理命令了。\n在整个 AOF 后台重写过程中，除了发生写时复制会对主进程造成阻塞，还有信号处理函数执行时也会对主进程造成阻塞，在其他时候，AOF 后台重写都不会阻塞主进程\nAOF总结 Redis 提供了三种将 AOF 日志写回硬盘的策略，分别是 Always、Everysec 和 No，这三种策略在可靠性上是从高到低，而在性能上则是从低到高。\n随着执行的命令越多，AOF 文件的体积自然也会越来越大，为了避免日志文件过大， Redis 提供了 AOF 重写机制，它会直接扫描数据中所有的键值对数据，然后为每一个键值对生成一条写操作命令，接着将该命令写入到新的 AOF 文件，重写完成后，就替换掉现有的 AOF 日志。重写的过程是由后台子进程完成的，这样可以使得主进程可以继续正常处理命令。\n用 AOF 日志的方式来恢复数据其实是很慢的，因为 Redis 执行命令由单线程负责的，而 AOF 日志恢复数据的方式是顺序执行日志里的每一条命令，如果 AOF 日志很大，这个「重放」的过程就会很慢了。\nRDB(redis database)快照 - 记录实际数据 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。\n快照怎么用 Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行：\n执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长， 会阻塞主线程 ； 执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以 避免主线程的阻塞 ； RDB 文件的加载工作是在服务器启动时自动执行的，Redis 并没有提供专门用于加载 RDB 文件的命令。\nRedis 还可以通过配置文件的选项来实现每隔一段时间自动执行一次 bgsave 命令，默认会提供以下配置：\n1 2 3 save 900 1 save 300 10 save 60 10000 别看选项名叫 save，实际上执行的是 bgsave 命令，也就是会创建子进程来生成 RDB 快照文件。\n只要满足上面条件的任意一个，就会执行 bgsave，它们的意思分别是：\n900 秒之内，对数据库进行了至少 1 次修改； 300 秒之内，对数据库进行了至少 10 次修改； 60 秒之内，对数据库进行了至少 10000 次修改。 这里提一点，Redis 的快照是 全量快照 ，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。\n这就是 RDB 快照的缺点，在服务器发生故障时，丢失的数据会比 AOF 持久化的方式更多，因为 RDB 快照是全量快照的方式，因此执行的频率不能太频繁，否则会影响 Redis 性能，而 AOF 日志可以以（appendfsync参数）秒级（everysec）的方式记录操作命令，所以丢失的数据就相对更少。\n执行快照时，数据能被修改吗？ 执行 bgsave 过程中，Redis 依然可以继续处理操作命令的，也就是数据是能被修改的。\n关键的技术就在于写时复制技术（Copy-On-Write, COW）。\n执行 bgsave 命令的时候，会通过 fork() 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个。\n只有在发生修改内存数据的情况时，物理内存才会被复制一份。\n这样的目的是为了减少创建子进程时的性能损耗，从而加快创建子进程的速度，毕竟创建子进程的过程中，是会阻塞主线程的。\n所以，创建 bgsave 子进程后，由于共享父进程的所有内存数据，于是就可以直接读取主线程（父进程）里的内存数据，并将数据写入到 RDB 文件。\n如果主线程（父进程）要 修改 共享数据里的某一块数据 （比如键值对 A）时，就会发生写时复制，于是这块数据的 物理内存就会被复制一份（键值对 A'） ，然后 主线程在这个数据副本（键值对 A'）进行修改操作 。与此同时， bgsave 子进程可以继续把原来的数据（键值对 A）写入到 RDB 文件 。\nbgsave 快照过程中，如果主线程修改了共享数据， 发生了写时复制后，RDB 快照保存的是原本的内存数据 ，而主线程刚修改的数据，是没办法在这一时间写入 RDB 文件的，只能交由下一次的 bgsave 快照。\nAOF\u0026amp;RDB合体 尽管 RDB 比 AOF 的数据恢复速度快，但是快照的频率不好把握：\n如果频率太低，两次快照间一旦服务器发生宕机，就可能会比较多的数据丢失； 如果频率太高，频繁写入磁盘和创建子进程会带来额外的性能开销。 那有没有什么方法不仅有 RDB 恢复速度快的优点和，又有 AOF 丢失数据少的优点呢？\n当然有，那就是将 RDB 和 AOF 合体使用，这个方法是在 Redis 4.0 提出的，该方法叫 混合使用 AOF 日志和内存快照 ，也叫混合持久化。\n如果想要开启混合持久化功能，可以在 Redis 配置文件将下面这个配置项设置成 yes：\n1 aof-use-rdb-preamble yes 混合持久化工作在 AOF 日志重写过程 。\n当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。\n也就是说，使用了混合持久化，AOF 文件的 前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据 。\n这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样 加载的时候速度会很快 。\n加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得 数据更少的丢失 。\nRedis分布式锁 分布式锁是用于分布式环境下并发控制的一种机制，用于控制某个资源在同一时刻只能被一个应用所使用 Redis 本身可以被多个客户端共享访问，正好就是一个共享存储系统，可以用来保存分布式锁，而且 Redis 的读写性能高，可以应对高并发的锁操作场景。\nsetnx「set if not exists」\n1 setnx key value Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：\n如果 key 不存在，则显示插入成功，可以用来表示加锁成功； 如果 key 存在，则会显示插入失败，可以用来表示加锁失败。 实现分布式锁流程 基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。\n加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成（Redis事务），所以，我们使用 SET 命令带上 NX 选项来实现加锁； 锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间； 锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端 （unique_value)； 上锁 满足这三个条件的分布式命令如下：\n1 SET lock_key unique_value NX PX 10000 lock_key 就是 key 键； unique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作； NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作； PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。 解锁 del key\n而解锁的过程就是将 lock_key 键删除（del lock_key），但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以，解锁的时候，我们要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除。\n判断锁的unique_value值，是否为加锁客户端 删除lock_key键 （del lock_key) 可以看到，解锁是有两个操作，这时就需要 Lua 脚本来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。\n1 2 3 4 5 6 // 释放锁时，先比较 unique_value 是否相等，避免锁的误释放 if redis.call(\u0026#34;get\u0026#34;,KEYS[1]) == ARGV[1] then return redis.call(\u0026#34;del\u0026#34;,KEYS[1]) else return 0 end 基于 Redis 实现分布式锁有什么优缺点？ 优点 性能高效（这是选择缓存实现分布式锁最核心的出发点）。 实现方便。很多研发工程师选择使用 Redis 来实现分布式锁，很大成分上是因为 Redis 提供了 setnx 方法，实现分布式锁很方便。 避免单点故障（因为 Redis 是跨集群部署的，自然就避免了单点故障）。 缺点 超时时间不好设置 。如果锁的超时时间设置过长，会影响性能，如果设置的超时时间过短会保护不到共享资源。比如在有些场景中（过短），一个线程 A 获取到了锁之后，由于业务代码执行时间可能比较长，导致超过了锁的超时时间，自动失效，注意 A 线程没执行完，后续线程 B 又意外的持有了锁，意味着可以操作共享资源，那么两个线程之间的共享资源就没办法进行保护了。\n那么如何合理设置超时时间呢？守护线程 我们可以基于续约的方式设置超时时间：先给锁设置一个超时时间，然后启动一个守护线程，让守护线程在一段时间后，重新设置这个锁的超时时间。实现方式就是：写一个守护线程，然后去判断锁的情况，当锁快失效的时候，再次进行续约加锁，当主线程执行完成后，销毁续约锁即可，不过这种方式实现起来相对复杂。 Redis 主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性 。如果在 Redis 主节点获取到锁后，在没有同步到其他节点时，Redis 主节点宕机了，此时新的 Redis 主节点依然可以获取锁，所以多个应用服务就可以同时获取到锁。（主从复制失败，从节点继续去拿锁）\n针对主从复制失败\nRedis 如何解决集群情况下分布式锁的可靠性？ 为了保证集群环境下分布式锁的可靠性，Redis 官方已经设计了一个分布式锁算法 Redlock（红锁）*过半得锁*。\n它是基于多个 Redis 节点的分布式锁，即使有节点发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作。官方推荐是至少部署 5 个 Redis 节点，而且都是主节点，它们之间没有任何关系，都是一个个孤立的节点。\nRedlock 算法的基本思路， 是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败 。（过半得锁）\n这样一来，即使有某个 Redis 节点发生故障，因为锁的数据在其他节点上也有保存，所以客户端仍然可以正常地进行锁操作，锁的数据也不会丢失。\nRedlock 算法加锁三个过程：\n第一步是，客户端获取当前时间（t1）。\n第二步是，客户端按顺序依次向 N 个 Redis 节点执行加锁操作：\n加锁操作使用 SET 命令，带上 NX，EX/PX 选项，以及带上客户端的唯一标识。 如果某个 Redis 节点发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给「加锁操作」设置一个超时时间（不是对「锁」设置超时时间，而是对「加锁操作」设置超时时间），加锁操作的超时时间需要远远地小于锁的过期时间，一般也就是设置为几十毫秒。 第三步是，一旦客户端从超过半数（大于等于 N/2+1）的 Redis 节点上成功获取到了锁，就再次获取当前时间（t2），然后计算计算整个加锁过程的总耗时（t2-t1）。如果 t2-t1 \u0026lt; 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败。\n可以看到，加锁成功要同时满足两个条件（ 简述：如果有超过半数的 Redis 节点成功的获取到了锁，并且总耗时没有超过锁的有效时间，那么就是加锁成功 ）：\n条件一：客户端从超过半数（大于等于 N/2+1）的 Redis 节点上成功获取到了锁； 条件二：客户端从大多数节点获取锁的总耗时（t2-t1）小于锁设置的过期时间。 加锁成功后，客户端需要重新计算这把锁的有效时间，计算的结果是「锁最初设置的过期时间」减去「客户端从大多数节点获取锁的总耗时（t2-t1）」。如果计算的结果已经来不及完成共享数据的操作了，我们可以释放锁，以免出现还没完成数据操作，锁就过期了的情况。\n加锁失败后，客户端向 所有 Redis 节点发起释放锁的操作 ，释放锁的操作和在单节点上释放锁的操作一样，只要执行释放锁的 Lua 脚本就可以了。\nbloom过滤器 本质上实通过容忍一定的错误率，来换取时空的高效性\n在哈希表基础上，忽略了冲突处理，从而省下了额外开销\nbit array，初始为0\ninsert(x) -\u0026gt; 对x进行多个hash(x) ,将对应位置置1\n当我们需要在大规模数据集中进行查询时，传统的算法比如哈希表、二叉搜索树等可能会面临内存不足的问题。Bloom Filter 是一种概率型数据结构，使用比较少的内存就能快速判断某个元素是否存在于一个集合之中，并且其空间和时间复杂度都是常数级别。\n具体来说，Bloom Filter 由若干个哈希函数和一个二进制向量组成。对于任意输入元素 x，通过哈希函数得到多个哈希值 h1(x),h2(x)\u0026hellip;hn(x)，每个哈希值对应二进制向量中的一个位置。将这些位置设置为 1，表示元素 x 存在于集合中。判断元素 y 是否在集合中时，只需检查 h1(y),h2(y),\u0026hellip;,h(y) 对应的二进制位置是否都是 1，如果有一个位置不是 1，则可以确定元素 y 不在集合中；否则，元素 y 可能存在于集合中（存在误判的概率）。\n都是1， 可能存在 不都是一，不存在 Bloom Filter 的误判率取决于哈希函数的数量和二进制向量的大小。如果哈希函数的数量增加，误判率将减小，但是计算代价也会增加。如果二进制向量的大小增加，误判率也会减小，但是空间开销也会增加。因此，在使用 Bloom Filter 时需要根据具体应用场景权衡误判率和计算/空间开销。\nBloom Filter 主要用于对元素进行快速查找或排重。一些常见的应用场景包括：\n网络爬虫：用于去重 URL，避免重复抓取同一页面。 分布式系统：用于快速判断某个键是否存在于缓存中，从而避免了频繁查询数据库的开销。 消息队列：用于保证每条消息只被处理一次。 需要注意的是，Bloom Filter 的特性决定了它不适用于所有场景。由于存在误判率，不能保证没有误判，只能保证不存在实际上不存在的元素。如果误判率较高，可能会导致应用出现 bug 或者数据不一致等问题。在使用 Bloom Filter 时，需要仔细考虑误判率和其他限制条件，确保其适用于特定场景。\n","permalink":"https://beardleon.github.io/posts/notes/redis/","summary":"\u003ch1 id=\"redis\"\u003eRedis\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e深入浅出走进Redis \u003ca href=\"https://mp.weixin.qq.com/s/ThVtw8TVuhxIyYxJy6sOWw\"\u003ehttps://mp.weixin.qq.com/s/ThVtw8TVuhxIyYxJy6sOWw\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"缓存穿透redis无key-压垮数据库\"\u003e\u003cstrong\u003e缓存穿透\u003c/strong\u003e（redis无key）-压垮数据库\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003ecache penetration\u003c/strong\u003e （刺穿）\u003c/p\u003e\n\u003cp\u003e问题描述：\u003cstrong\u003ekey对应的数据在数据源并不存在\u003c/strong\u003e，每次针对此key的请求从缓存获取不到，请求都会压到数据源，从而可能压垮数据源。比如用一个不存在的用户id获取用户信息，\u003cstrong\u003e不论缓存还是数据库都没有\u003c/strong\u003e，若黑客利用此漏洞进行攻击可能压垮数据库。\u003c/p\u003e\n\u003cp\u003e解决方案：（1）对\u003cstrong\u003e空值缓存\u003c/strong\u003e：如果一个查询返回的数据为空（不管是数据是否不存在），我们仍然把这个空结果（null）进行缓存，设置空结果的过期时间会很短，最长不超过五分钟。（2）设置可访问的名单（白名单）：使用bitmaps类型定义一个可以访问的名单，名单id作为bitmaps的偏移量，每次访问和bitmap里面的id进行比较，如果访问id不在bitmaps里面，进行拦截，不允许访问。（3）采用\u003cstrong\u003e布隆过滤器\u003c/strong\u003e：将所有可能存在的数据哈希到一个\u003cstrong\u003e足够大的bitmaps\u003c/strong\u003e中，一个一定不存在的数据会被 这个bitmaps拦截掉，从而避免了对底层存储系统的查询压力。（\u003cstrong\u003e加一层防护判断）\u003c/strong\u003e（4）进行实时监控：当发现Redis的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，可以设置黑名单限制服务。\u003c/p\u003e\n\u003ch2 id=\"缓存击穿redis热点key突然过期-大量并发访问单key-被击穿数据库\"\u003e\u003cstrong\u003e缓存击穿\u003c/strong\u003e（redis热点key突然过期）-大量并发访问单key-被击穿数据库\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003ecache breakdown\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e问题描述：\u003cstrong\u003ekey对应的数据存在，但在redis中过期\u003c/strong\u003e，此时若有\u003cstrong\u003e大量并发\u003c/strong\u003e请求过来，这些请求发现缓存过期一般都\u003cstrong\u003e会从后端DB加载数据并回设到缓存\u003c/strong\u003e，这个时候大并发的请求可能会瞬间把后端DB压垮。\u003c/p\u003e\n\u003cp\u003e解决问题：（1）预先设置热门数据：在redis高峰访问之前，把一些热门数据提前存入到redis里面，加大这些热门数据key的时长。\u003cstrong\u003e（淘宝提前热门缓存）\u003c/strong\u003e（2）实时调整：现场监控哪些数据热门，实时调整key的\u003cstrong\u003e过期时长\u003c/strong\u003e。（3）使用锁：就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db；先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX）去set一个mutex key；当操作返回成功时，再进行load db的操作，并回设缓存,最后删除mutex key；当操作返回失败，证明有线程在load db，当前线程睡眠一段时间再重试整个get缓存的方法（\u003cstrong\u003e搞个分布式锁，但一线程去访问db，阻塞其他的）\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3 id=\"什么是缓存击穿\"\u003e\u003cstrong\u003e什么是缓存击穿\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e平常在高并发系统中，会出现大量的请求同时查询一个 \u003ccode\u003ekey\u003c/code\u003e的情况，假如此时这个热 \u003ccode\u003ekey\u003c/code\u003e刚好失效了，就会导致大量的请求都打到数据库上面去，这种现象就是缓存击穿。缓存击穿和缓存雪崩有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了DB，而缓存击穿则是指一个key非常热点，在不停的扛着高并发，高并发集中对着这\u003cstrong\u003e一个点\u003c/strong\u003e进行访问，如果这个key在失效的瞬间，持续的并发到来就会穿破缓存，直接请求到数据库，就像一个完好无损的桶上凿开了一个洞，造成某一时刻数据库请求量过大，压力剧增！\u003c/p\u003e\n\u003ch3 id=\"如何解决\"\u003e\u003cstrong\u003e如何解决\u003c/strong\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e方法一我们简单粗暴点，直接让热点数据永远不过期，定时任务定期去刷新数据就可以了。不过这样设置需要区分场景，比如某宝首页可以这么做。\u003c/li\u003e\n\u003cli\u003e方法二为了避免出现缓存击穿的情况，我们可以在第一个请求去查询数据库的时候对他加一个互斥锁，其余的查询请求都会被阻塞住，直到锁被释放，后面的线程进来发现已经有缓存了，就直接走缓存，从而保护数据库。但是也是由于它会阻塞其他的线程，此时系统吞吐量会下降。需要结合实际的业务去考虑是否要这么做。\u003c/li\u003e\n\u003cli\u003e方法三\u003cbr /\u003e\n方法三就是singleflight的设计思路，也会使用互斥锁，但是相对于方法二的加锁粒度会更细，这里先简单总结一下singleflight的设计原理，后面看源码在具体分析。\u003cbr /\u003e\nsingleflightd的设计思路就是将一组相同的请求合并成一个请求，使用 \u003ccode\u003emap\u003c/code\u003e存储，\u003cstrong\u003e只会有一个请求到达mysql\u003c/strong\u003e，使用 \u003ccode\u003esync.waitgroup\u003c/code\u003e包进行同步，对所有的请求返回相同的结果。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"缓存雪崩redis有多key无value-多key被击穿\"\u003e\u003cstrong\u003e缓存雪崩\u003c/strong\u003e（redis有多key无value）-多key被击穿\u003c/h2\u003e\n\u003cp\u003e问题描述：\u003cstrong\u003ekey对应的数据存在，但在redis中过期\u003c/strong\u003e，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。缓存雪崩与缓存击穿的区别在于这里针对很多key缓存，后者则是某一个key。\u003c/p\u003e\n\u003cp\u003e解决方案：（1）构建多级缓存架构：nginx缓存 + redis缓存 +其他缓存（ehcache等）。（2）使用锁或队列：用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上（\u003cstrong\u003e消息队列）\u003c/strong\u003e。不适用高并发情况。（3）设置\u003cstrong\u003e过期标志更新缓存\u003c/strong\u003e：记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程在后台去更新实际key的缓存。（4）将\u003cstrong\u003e缓存失效时间分散开\u003c/strong\u003e：比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。\u003c/p\u003e\n\u003ch2 id=\"持久化aof--rdb\"\u003e持久化AOF \u0026amp; RDB\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eAppend- Only- File日志 \u003cstrong\u003e默认不开启\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eRDB快照\u003c/li\u003e\n\u003cli\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eAOF\u003c/strong\u003e 文件的内容是\u003cstrong\u003e操作命令\u003c/strong\u003e（写命令）；\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRDB\u003c/strong\u003e 文件的内容是二进制\u003cstrong\u003e数据\u003c/strong\u003e。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"append--only--file持久化操作命令如何实现\"\u003eAppend- Only- File持久化操作命令如何实现？\u003c/h3\u003e\n\u003cp\u003e如果 Redis 每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里，然后重启 Redis 的时候，先去读取这个文件里的命令，并且执行它，这不就相当于恢复了缓存数据了吗？\u003cimg loading=\"lazy\" src=\"/posts/notes/redis/posts/notes/redis/1.png\"\u003e\u003c/p\u003e\n\u003cp\u003e这种保存写操作命令到日志的持久化方式，就是 Redis 里的 \u003cstrong\u003eAOF( \u003cem\u003eAppend Only File\u003c/em\u003e )\u003c/strong\u003e 持久化功能，\u003cstrong\u003e注意只会记录写操作命令，读操作命令是不会被记录的\u003c/strong\u003e（\u003cstrong\u003e读不被记录）\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eAOF 日志文件其实就是普通的文本，我们可以通过 \u003ccode\u003ecat\u003c/code\u003e 命令查看里面的内容，不过里面的内容如果不知道一定的规则的话，可能会看不懂。\u003c/p\u003e","title":"深入浅出走进Redis"}]